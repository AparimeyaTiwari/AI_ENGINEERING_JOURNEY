{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1fc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network from scratch#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fc4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0368b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1-> Create Network Architecture\n",
    "L = 3 # number of layers (excluding hidden layer)\n",
    "n = [2,3,3,1] #n(l) = No of nodes in each layer\n",
    "\n",
    "#STEP 2-> CREATE WEIGHTS\n",
    "'''\n",
    "now we have n[l]*n[l-1] weights per layer\n",
    "hence-> we created matrixes of the same size\n",
    "'''\n",
    "W1 = np.random.randn(n[1],n[0]) \n",
    "W2 = np.random.randn(n[2],n[1])\n",
    "W3 = np.random.randn(n[3],n[2])\n",
    "\n",
    "'''\n",
    "Number of biases = Number of nodes in that layer\n",
    "Input layer has no bias, hence we start off with layer 1\n",
    "'''\n",
    "B1 = np.random.randn(n[1],1)\n",
    "B2 = np.random.randn(n[2],1)\n",
    "B3 = np.random.randn(n[3],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749909fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 -> create training data and labels\n",
    "def prepare_data():\n",
    "  X = np.array([\n",
    "      [150, 70],\n",
    "      [254, 73],\n",
    "      [312, 68],\n",
    "      [120, 60],\n",
    "      [154, 61],\n",
    "      [212, 65],\n",
    "      [216, 67],\n",
    "      [145, 67],\n",
    "      [184, 64],\n",
    "      [130, 69]\n",
    "  ])\n",
    "  y = np.array([0,1,1,0,0,1,1,0,1,0])\n",
    "  m = 10\n",
    "  AO = X.T\n",
    "  Y = y.reshape(n[L],m)\n",
    "\n",
    "  return AO,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecf275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4 -> Define activation function\n",
    "def sigmoid(arr):\n",
    "    return 1/(1+np.exp(-1*arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7c1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5 -> Define feed forward network\n",
    "\n",
    "'''Logic\n",
    "https://miro.medium.com/v2/resize:fit:1100/format:webp/0*GlvBqiZhpbf55Mm7.png\n",
    "We take -> Z = Weights * Values + Bias\n",
    "o/p -> Sigmoid(Z)\n",
    "This continues for each layer\n",
    "\n",
    "'''\n",
    "\n",
    "def feed_forward(A0):\n",
    "    Z1 = W1@AO + B1\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    Z2 = W2@A1 + B2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    Z3 = W3@A2 + B3\n",
    "    A3 = sigmoid(Z3)\n",
    "\n",
    "    y_pred = A3\n",
    "    return y_pred\n",
    "\n",
    "AO,Y = prepare_data()\n",
    "y_pred = feed_forward(AO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8207e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42191997 0.42191997 0.42191997 0.42191997 0.42191997 0.42191997\n",
      "  0.42191997 0.42191997 0.42191997 0.42191997]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520b6218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7054912925544268)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and calculate the loss function (Binary cross entropy)\n",
    "'''\n",
    "L(ŷiyi) = - (yiln(ŷi)+ (1-yi)ln(1-ŷi))\n",
    "Then take avg weighted sum\n",
    "\n",
    "Case 1) yi = 0\n",
    "L(ŷiyi) = -ln(1-ŷi)\n",
    "\n",
    "If ŷi = 0 -> loss = 0 hence correct\n",
    "If ŷi = 1 -> loss = -infinity hence correct\n",
    "\n",
    "Case 2) yi = 1\n",
    "L(ŷiyi) = -yiln(ŷi) \n",
    "\n",
    "If ŷi = 0 -> loss = -infinity hence correct\n",
    "If ŷi = 1 -> loss = 0 hence correct\n",
    "'''\n",
    "\n",
    "def cost(y_pred,y):\n",
    "    \"\"\"\n",
    "    y_hat should be a n^L x m matrix\n",
    "    y should be a n^L x m matrix\n",
    "    \"\"\"\n",
    "    losses = -((y*np.log(y_pred))+(1-y)*np.log(1-y_pred))\n",
    "    m = y_pred.reshape(-1).shape[0]\n",
    "    mean_loss = (1/m) * (np.sum(losses,axis=1))\n",
    "\n",
    "    return np.sum(mean_loss)\n",
    "\n",
    "cost(y_pred,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a6ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a9465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58fc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4992af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62faef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec70c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
